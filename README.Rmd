---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, 
  comment = "#>",
  fig.path = "README-"  
)
```

# rvest <img src="man/figures/logo.png" align="right" height="139"/>

<!-- badges: start -->

[![CRAN status](https://www.r-pkg.org/badges/version/rvest)](https://cran.r-project.org/package=rvest) [![R-CMD-check](https://github.com/tidyverse/rvest/workflows/R-CMD-check/badge.svg)](https://github.com/tidyverse/rvest/actions) [![Codecov test coverage](https://codecov.io/gh/tidyverse/rvest/branch/master/graph/badge.svg)](https://codecov.io/gh/tidyverse/rvest?branch=master)

<!-- badges: end -->

rvest helps you scrape information from web pages.
It is designed to work with [magrittr](https://github.com/smbache/magrittr) to make it easy to express common web scraping tasks, inspired by libraries like [beautiful soup](https://www.crummy.com/software/BeautifulSoup/).

If you're scraping multiple pages, I highly recommend using rvest in concert with [polite](https://dmi3kno.github.io/polite/).
The polite package ensures that you're respecting the [robots.txt](https://en.wikipedia.org/wiki/Robots_exclusion_standard) and not hammering the site with too many requests.

## Installation

```{r, eval = FALSE}
# The easiest way to get rvest is to install the whole tidyverse:
install.packages("tidyverse")

# Alternatively, install just rvest:
install.packages("dplyr")
```

## Usage

```{r, message = FALSE}
library(rvest)
starwars <- read_html("https://rvest.tidyverse.org/articles/starwars.html")

films <- starwars %>% html_elements("section")
films

title <- films %>% 
  html_element("h2") %>% 
  html_text(trim = TRUE)
title

episode <- films %>% 
  html_element("h2") %>% 
  html_attr("data-id") %>% 
  readr::parse_integer()
episode

released <- films %>% 
  html_element("p:nth-child(2)") %>% 
  html_text(trim = TRUE) %>% 
  gsub("Released: ", "", .) %>% 
  readr::parse_date()
released

crawl <- films %>% 
  html_element("div") %>%
  html_text2()
cat(crawl[[1]])
```

## Key functions

Once you have read a HTML document with `read_html()`, you can:

-   Select parts of a document using CSS selectors, `html_elements(doc, "table td")`, or XPath expressions, `html_elements(doc, xpath = "//table//td")`).
    If you haven't heard of [selectorgadget](http://selectorgadget.com/), make sure to read `vignette("selectorgadget")` to learn about it.

-   Extract data from text with `html_text2()` and from attributes with `html_attr()`.

-   Parse tables into data frames with `html_table()`.

-   Navigate around a website as if you're in a browser with `html_session()`, `jump_to()`, `follow_link()`, `back()`, and `forward()`.
    Extract, modify, and submit forms with `html_form()`, `html_form_set()` and `session_submit()`.

## Inspirations

-   Python: [RoboBrowser](http://robobrowser.readthedocs.org/en/latest/readme.html), [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/).

## Code of Conduct

Please note that the rvest project is released with a [Contributor Code of Conduct](https://rvest.tidyverse.org/CODE_OF_CONDUCT.html).
By contributing to this project, you agree to abide by its terms.
